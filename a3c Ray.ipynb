{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch import tensor\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import cv2\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import ray\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model construction\n",
    "\n",
    "class A3C(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(A3C, self).__init__()\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=3, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        convw = conv2d_size_out(210, 8, 4)\n",
    "        convw = conv2d_size_out(convw, 4, 2)\n",
    "        convw = conv2d_size_out(convw, 3, 1)\n",
    "\n",
    "        convh = conv2d_size_out(160, 8, 4)\n",
    "        convh = conv2d_size_out(convh, 4, 2)\n",
    "        convh = conv2d_size_out(convh, 3, 1)\n",
    "\n",
    "        linear_input_size = convw * convh * 64\n",
    "        print(\"linear_input_size\", linear_input_size)\n",
    "        self.lstm_i_dim = 512  # input dimension of LSTM\n",
    "        self.lstm_h_dim = 512  # output dimension of LSTM\n",
    "        self.lstm_N_layer = 1  # number of layers of LSTM\n",
    "        self.Conv2LSTM = nn.Linear(linear_input_size, self.lstm_i_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_i_dim, hidden_size=self.lstm_h_dim, num_layers=self.lstm_N_layer)\n",
    "\n",
    "        self.fc_pi = nn.Linear(self.lstm_h_dim, self.num_actions)\n",
    "        self.fc_v = nn.Linear(self.lstm_h_dim, 1)\n",
    "\n",
    "    def pi(self, x, softmax_dim=1):\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "\n",
    "    def v(self, x):\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "\n",
    "    def forward(self, x, hidden, softmax_dim=2):\n",
    "        x = x/255.0\n",
    "        if (len(x.shape) < 4):  # 배치학습이 아닐 때\n",
    "            x = x.unsqueeze(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.contiguous()  # x torch.Size([1, 64, 22, 16])\n",
    "        x = x.view(x.size(0), -1)  # x torch Size([1, 22528])\n",
    "        x = F.relu(self.Conv2LSTM(x))\n",
    "        x = x.unsqueeze(1)  # x torch Size([1,1,1024])\n",
    "        x, new_hidden = self.lstm(x, hidden)\n",
    "        return x, new_hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-3aa22c434dbd>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-3aa22c434dbd>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class Actor():\n",
    "    def __init__(self, model, env, gamma, batch_size, max_epi, agent_num):\n",
    "        # Network\n",
    "        self.model = model\n",
    "\n",
    "        # Hyperparmeters\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # env\n",
    "        self.env = env\n",
    "        self.print_interval = 20\n",
    "        self.score = 0.0\n",
    "        self.max_epi = max_epi\n",
    "        self.agent_num = agent_num\n",
    "\n",
    "        # data for calculating loss\n",
    "        self.data = []\n",
    "\n",
    "    def put_data(self, item):\n",
    "        self.data.append(item)\n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, done = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            done_lst.append([done_mask])\n",
    "        s_batch = torch.stack(s_lst).float().to(device)\n",
    "        a_batch = torch.tensor(a_lst).to(device)\n",
    "        r_batch = torch.tensor(r_lst).float().to(device)\n",
    "        s_prime_batch = torch.stack(s_prime_lst).float().to(device)\n",
    "        done_batch = torch.tensor(done_lst).float().to(device)\n",
    "\n",
    "        self.data = []\n",
    "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
    "    \n",
    "    def explore(self):\n",
    "        done = False\n",
    "        s = self.env.reset()\n",
    "        s = torch.from_numpy(s).permute(2, 0, 1).to(device)\n",
    "        hidden = (Variable(torch.zeros(1, 1, 512).float().to(device=device)),\n",
    "                  Variable(torch.zeros(1, 1, 512).float().to(device=device)))\n",
    "        self.score = 0.0\n",
    "        \n",
    "        \n",
    "        while not done:\n",
    "            self.env.render()\n",
    "            for t in range(n_rollout):\n",
    "                x, hidden = self.model.forward(s.float(), hidden)\n",
    "                prob = self.model.pi(x, softmax_dim=2)\n",
    "                m = Categorical(prob)\n",
    "                a = m.sample().item()\n",
    "\n",
    "                s_prime, r, done, info = self.env.step(a)\n",
    "                s_prime = torch.from_numpy(s_prime).permute(2, 0, 1).to(device)\n",
    "                self.put_data((s, a, r, s_prime, done)) # 데이터를 쌓는 부분\n",
    "\n",
    "                s = s_prime\n",
    "                self.score += r\n",
    "                if done:\n",
    "                    break\n",
    "        \n",
    "    def accumulate_gradients(self):\n",
    "        s, a, r, s_prime, done = self.make_batch()  # all tensors size must be [10,1]\n",
    "        x_prime, _ = self.model.forward(s_prime, hidden)\n",
    "        v_prime = self.model.v(x_prime)\n",
    "        v_prime = v_prime.squeeze(1)\n",
    "        td_target = r + self.gamma * v_prime * done\n",
    "\n",
    "        x, _ = self.model.forward(s, hidden)\n",
    "        v = self.model.v(x)\n",
    "        v = v.squeeze(1)\n",
    "\n",
    "        delta = td_target - v\n",
    "        pi = self.model.pi(x, softmax_dim=2)\n",
    "        a = a.unsqueeze(1)\n",
    "        pi_a = pi.gather(2, a)\n",
    "\n",
    "        # Policy Loss + Value Loss\n",
    "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(v, td_target.detach())\n",
    "        loss.mean().backward\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, env, lr, gamma, batch_size, max_epi, save_path):\n",
    "        # Network and Optimizer\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Hyperparmeters\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "\n",
    "        # env\n",
    "        self.env = env\n",
    "        self.print_interval = 20\n",
    "        \n",
    "        # global shared counter T\n",
    "        self.max_epi = max_epi \n",
    "\n",
    "        self.save_path = save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@ray.remote\n",
    "class Actor_Learner():\n",
    "    def __init__(self, model, env, lr, gamma, batch_size, max_epi, agent_num, save_path):\n",
    "        # Network, Optimizer\n",
    "        self.learner_model = model.cuda()\n",
    "        self.actor_model = model.cpu()\n",
    "        self.optimizer = optim.Adam(self.learner_model.parameters(), lr=lr)\n",
    "        \n",
    "        # Hyperparmeters\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # global, thread counter\n",
    "        self.T = 0\n",
    "        self.T_max = 10000\n",
    "        self.t = 1\n",
    "        self.t_max = 40\n",
    "        \n",
    "        # env\n",
    "        self.env = env\n",
    "        self.print_interval = 20\n",
    "        self.score = 0.0\n",
    "        self.max_epi = max_epi\n",
    "        self.agent_num = agent_num\n",
    "\n",
    "        # data for n-step training\n",
    "        self.data = []\n",
    "\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def put_data(self, item):\n",
    "        self.data.append(item)\n",
    "\n",
    "    def make_batch(self):\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\n",
    "        for transition in self.data:\n",
    "            s, a, r, s_prime, done = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            done_lst.append([done_mask])\n",
    "        s_batch = torch.stack(s_lst).float().to(device)\n",
    "        a_batch = torch.tensor(a_lst).to(device)\n",
    "        r_batch = torch.tensor(r_lst).float().to(device)\n",
    "        s_prime_batch = torch.stack(s_prime_lst).float().to(device)\n",
    "        done_batch = torch.tensor(done_lst).float().to(device)\n",
    "\n",
    "        self.data = []\n",
    "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\n",
    "\n",
    "    def calculate_loss(self, hidden):\n",
    "        s, a, r, s_prime, done = self.make_batch()  # all tensors size must be [10,1]\n",
    "        x_prime, _ = self.actor_model.forward(s_prime, hidden)\n",
    "        v_prime = self.actor_model.v(x_prime)\n",
    "        v_prime = v_prime.squeeze(1)\n",
    "        td_target = r + self.gamma * v_prime * done\n",
    "\n",
    "        x, _ = self.actor_model.forward(s, hidden)\n",
    "        v = self.actor_model.v(x)\n",
    "        v = v.squeeze(1)\n",
    "\n",
    "        delta = td_target - v\n",
    "        pi = self.actor_model.pi(x, softmax_dim=2)\n",
    "        a = a.unsqueeze(1)\n",
    "        pi_a = pi.gather(2, a)\n",
    "\n",
    "        # Policy Loss + Value Loss\n",
    "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(v, td_target.detach())\n",
    "\n",
    "        loss.mean().backward\n",
    "    \n",
    "    def accumulate_gradients(self):\n",
    "        for actor_net, learner_net in zip(self.actor_model.named_parameters(), self.learner_model.named_parameters()):\n",
    "                learner_net[1].data.grad = actor_net[1].data.grad.clone\n",
    "    \n",
    "    def train(self):\n",
    "        for n_epi in range(self.T_max):\n",
    "            # Reset gradients and Synchronize thread params with global params\n",
    "            self.optimizer.zero_grad()                                     \n",
    "            self.actor_model = deepcopy(self.learner_model).cpu            \n",
    "            t_start = self.t\n",
    "            \n",
    "            # state initialiaztion\n",
    "            device = 'cpu'\n",
    "            done = False\n",
    "            s = self.env.reset()\n",
    "            s = torch.from_numpy(s).permute(2, 0, 1).to(device)\n",
    "            hidden = (Variable(torch.zeros(1, 1, 512).float().to(device=device)),\n",
    "                      Variable(torch.zeros(1, 1, 512).float().to(device=device)))            \n",
    "            \n",
    "            while not done:\n",
    "                self.env.render()\n",
    "                for t in range(self.t_max):\n",
    "                    x, hidden = self.actor_model.forward(s.float(), hidden)\n",
    "                    prob = self.actor_model.pi(x, softmax_dim=2)\n",
    "                    m = Categorical(prob)\n",
    "                    a = m.sample().item()\n",
    "                    print(a)\n",
    "                    s_prime, r, done, info = self.env.step(a)\n",
    "                    s_prime = torch.from_numpy(s_prime).permute(2, 0, 1).to(device)\n",
    "                    self.put_data((s, a, r, s_prime, done)) # 데이터를 쌓는 부분\n",
    "\n",
    "                    s = s_prime\n",
    "                    self.score += r\n",
    "\n",
    "                    if done:\n",
    "                        break\n",
    "                self.calculate_loss(hidden)\n",
    "                self.accumulate_gradients()\n",
    "            self.optimizer.step()\n",
    "                \n",
    "        self.env.close()\n",
    "        \n",
    "    def save_model(self):\n",
    "        torch.save({'model_state_dict': self.learner_model.state_dict()}, self.save_path + 'a3c_lstm2.pth')\n",
    "        print(\"model saved\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3f68a533b944>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _java_worker_options, _code_search_path, _temp_dir, _load_code_from_local, _lru_evict, _metrics_export_port, _object_spilling_config, _system_config)\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m             raise RuntimeError(\"Maybe you called ray.init twice by accident? \"\n\u001b[0m\u001b[0;32m    665\u001b[0m                                \u001b[1;34m\"This error can be suppressed by passing in \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                \u001b[1;34m\"'ignore_reinit_error=True' or by calling \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_input_size 22528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function SimpleImageViewer.__del__ at 0x0000016CEDE50CA8>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 382, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 378, in close\n",
      "    self.window.close()\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 285, in close\n",
      "    super(Win32Window, self).close()\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\pyglet\\window\\__init__.py\", line 823, in close\n",
      "    app.windows.remove(self)\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\_weakrefset.py\", line 109, in remove\n",
      "    self.data.remove(ref(item))\n",
      "KeyError: (<weakref at 0x0000016CEDE56AE8; to 'Win32Window' at 0x0000016D0E26D508>,)\n",
      "2021-01-29 18:07:17,933\tERROR worker.py:999 -- print_logs: Error while reading from socket: (10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None)\n",
      "2021-01-29 18:07:17,933\tERROR worker.py:1093 -- listen_error_messages_raylet: Error while reading from socket: (10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None)\n",
      "2021-01-29 18:07:17,933\tERROR import_thread.py:89 -- ImportThread: Error while reading from socket: (10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None)\n"
     ]
    }
   ],
   "source": [
    "# Multi agent\n",
    "\n",
    "def main():\n",
    "\n",
    "    env = gym.make(\"Breakout-v4\")\n",
    "    \n",
    "    lr = 0.0005\n",
    "    gamma = 0.98\n",
    "    batch_size = 32\n",
    "    buffer_limit = 50000\n",
    "    max_epi = 100000\n",
    "    agent_num = 1\n",
    "    save_path = os.curdir\n",
    "    \n",
    "    model = A3C(num_actions=4)\n",
    "    agent = Actor_Learner(model, env, lr, gamma, batch_size, max_epi, 0, save_path)\n",
    "\n",
    "\n",
    "\n",
    "    st = time.time()\n",
    "    agent.train()\n",
    "    #result = [agent.train.remote()]\n",
    "    #agent.save_model.remote()\n",
    "    #ray.get(result)\n",
    "    et = time.time()\n",
    "    print(et - st)\n",
    "    env.close()\n",
    "    \n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "state = np.random.random((64, 64, 4))\n",
    "action = np.random.random(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2050586  0.46898444 0.20006773 0.82962584 0.27473953 0.55642393\n",
      " 0.91561391 0.75505885]\n"
     ]
    }
   ],
   "source": [
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 8)\n",
      "[[[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]\n",
      "\n",
      " [[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]\n",
      "\n",
      " [[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]\n",
      "\n",
      " [[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]\n",
      "\n",
      " [[0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  ...\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]\n",
      "  [0.2050586  0.46898444 0.20006773 ... 0.55642393 0.91561391 0.75505885]]]\n"
     ]
    }
   ],
   "source": [
    "action_channel = np.ones(shape=list(state.shape[:-1]) + [8], dtype=state.dtype)\n",
    "print(action_channel.shape)\n",
    "print(action_channel * action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in action:\n",
    "    for i in action_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
