{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy # 모델 파라미터를 복사하기 위한 라이브러리 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 12:50:57,890\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.22',\n",
       " 'raylet_ip_address': '192.168.0.22',\n",
       " 'redis_address': '192.168.0.22:6379',\n",
       " 'object_store_address': 'tcp://127.0.0.1:52941',\n",
       " 'raylet_socket_name': 'tcp://127.0.0.1:58691',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': 'C:\\\\Users\\\\KUKJIN~1\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2021-01-29_12-50-55_923578_39060',\n",
       " 'metrics_export_port': 43394,\n",
       " 'node_id': '53bfe28a944112d73498a91621f9bd1db6fd29e6'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 12:51:01,840\tWARNING worker.py:1091 -- The dashboard on node DESKTOP-ESV82HP failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 962, in <module>\n",
      "    metrics_export_address=metrics_export_address)\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 512, in __init__\n",
      "    build_dir = setup_static_dir(self.app)\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 411, in setup_static_dir\n",
      "    \"&& npm run build)\", build_dir)\n",
      "FileNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/dashboard/client && npm ci && npm run build): 'c:\\\\users\\\\kukjinkim\\\\anaconda3\\\\envs\\\\minerl\\\\lib\\\\site-packages\\\\ray\\\\dashboard\\\\client/build'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class A3C(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(A3C, self).__init__()\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=8, stride=4)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=3, stride=2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        convw = conv2d_size_out(210, 8, 4)\n",
    "        convw = conv2d_size_out(convw, 4, 2)\n",
    "        convw = conv2d_size_out(convw, 3, 1)\n",
    "\n",
    "        convh = conv2d_size_out(160, 8, 4)\n",
    "        convh = conv2d_size_out(convh, 4, 2)\n",
    "        convh = conv2d_size_out(convh, 3, 1)\n",
    "\n",
    "        linear_input_size = convw * convh * 64\n",
    "        print(\"linear_input_size\", linear_input_size)\n",
    "        self.lstm_i_dim = 512  # input dimension of LSTM\n",
    "        self.lstm_h_dim = 512  # output dimension of LSTM\n",
    "        self.lstm_N_layer = 1  # number of layers of LSTM\n",
    "        self.Conv2LSTM = nn.Linear(linear_input_size, self.lstm_i_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.lstm_i_dim, hidden_size=self.lstm_h_dim, num_layers=self.lstm_N_layer)\n",
    "\n",
    "        self.fc_pi = nn.Linear(self.lstm_h_dim, self.num_actions)\n",
    "        self.fc_v = nn.Linear(self.lstm_h_dim, 1)\n",
    "\n",
    "    def pi(self, x, softmax_dim=1):\n",
    "        x = self.fc_pi(x)\n",
    "        prob = F.softmax(x, dim=softmax_dim)\n",
    "        return prob\n",
    "\n",
    "    def v(self, x):\n",
    "        v = self.fc_v(x)\n",
    "        return v\n",
    "\n",
    "    def forward(self, x, hidden, softmax_dim=2):\n",
    "        x = x/255.0\n",
    "        if (len(x.shape) < 4):  # 배치학습이 아닐 때\n",
    "            x = x.unsqueeze(0)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = x.contiguous()  # x torch.Size([1, 64, 22, 16])\n",
    "        x = x.view(x.size(0), -1)  # x torch Size([1, 22528])\n",
    "        x = F.relu(self.Conv2LSTM(x))\n",
    "        x = x.unsqueeze(1)  # x torch Size([1,1,1024])\n",
    "        x, new_hidden = self.lstm(x, hidden)\n",
    "        return x, new_hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_input_size 22528\n",
      "tensor([[[-0.0097, -0.7700, -0.2625,  ..., -1.8247,  0.7748,  0.2273],\n",
      "         [-0.5518, -1.1822,  0.0720,  ...,  1.3301, -0.0274,  0.5967],\n",
      "         [-0.9266,  0.1560,  0.4429,  ...,  0.9406, -0.4538,  1.5117],\n",
      "         ...,\n",
      "         [-0.9680,  1.7315, -1.0140,  ..., -0.6431, -0.4889, -0.1594],\n",
      "         [ 0.0366, -0.2669, -1.5177,  ..., -2.2529, -1.1450, -1.4923],\n",
      "         [ 0.9742,  0.4543, -0.3285,  ..., -0.6975, -0.0850,  2.0572]],\n",
      "\n",
      "        [[ 1.1047, -2.2310, -0.2101,  ...,  1.0271, -0.8119, -0.6909],\n",
      "         [ 0.5769,  1.5306, -0.0727,  ..., -0.0725,  0.2916, -0.6817],\n",
      "         [-0.0883, -0.7771, -0.7282,  ...,  0.4471,  0.0279, -0.0940],\n",
      "         ...,\n",
      "         [ 0.8975, -2.6726, -1.1230,  ..., -0.1625, -1.5088, -0.0213],\n",
      "         [ 0.2520, -0.7394, -0.1420,  ...,  0.3636,  0.5944,  0.1619],\n",
      "         [-0.5319, -0.2252, -1.1208,  ...,  1.6820,  0.9883, -0.4077]],\n",
      "\n",
      "        [[-0.4958,  0.2344, -0.0498,  ...,  1.2414,  0.1514, -1.1733],\n",
      "         [ 1.3670,  1.8236, -0.4096,  ...,  0.2224,  0.9491,  1.4020],\n",
      "         [ 2.8444,  0.6394,  1.3519,  ..., -1.7845,  0.9167,  1.5805],\n",
      "         ...,\n",
      "         [ 0.1301, -0.1512, -1.2625,  ...,  2.5254, -1.5845,  1.0918],\n",
      "         [-1.4758, -1.0751,  0.0573,  ...,  0.6592,  1.7070,  0.3802],\n",
      "         [ 1.6726, -0.7479,  2.2568,  ...,  0.7850, -0.4323, -0.7268]]],\n",
      "       device='cuda:0')\n",
      "torch.Size([3, 210, 160])\n",
      "tensor([[[-0.0492,  0.0558,  0.0097, -0.0214, -0.0192, -0.0028, -0.0593,\n",
      "          -0.0082,  0.0517,  0.0671, -0.0380,  0.0333,  0.0140,  0.0282,\n",
      "           0.0193,  0.0758,  0.0039,  0.0027,  0.0013,  0.0256, -0.0677,\n",
      "           0.0071,  0.0299, -0.0120,  0.0178,  0.0081,  0.0585, -0.1317,\n",
      "          -0.1114, -0.0643,  0.0110, -0.0172, -0.0161,  0.0403,  0.0125,\n",
      "          -0.1012,  0.0132,  0.0057,  0.0005, -0.0592,  0.0321,  0.0695,\n",
      "           0.0721,  0.0313, -0.0040,  0.0057, -0.0056, -0.0109, -0.0087,\n",
      "           0.1180,  0.0146, -0.0502, -0.0129,  0.0134,  0.0549,  0.0113,\n",
      "           0.0056, -0.0133,  0.0172, -0.0108,  0.0623, -0.0999, -0.0495,\n",
      "          -0.0381,  0.0468, -0.0059,  0.0329,  0.0210,  0.0112,  0.0596,\n",
      "          -0.0167, -0.0599,  0.0747, -0.0547,  0.0175, -0.0708, -0.0464,\n",
      "          -0.0102,  0.0097, -0.0011,  0.0150,  0.0049, -0.0342,  0.0112,\n",
      "          -0.0282,  0.0074, -0.0037,  0.0150, -0.0429, -0.0502,  0.0542,\n",
      "          -0.0009,  0.0641, -0.0091,  0.0384, -0.0503,  0.0187, -0.0249,\n",
      "          -0.0040,  0.0140,  0.0481,  0.0322, -0.0389,  0.0156, -0.0472,\n",
      "          -0.0007, -0.0663, -0.0044,  0.0272, -0.0159,  0.0092, -0.0108,\n",
      "           0.0468,  0.0473,  0.1034,  0.0704, -0.0520, -0.0077, -0.0187,\n",
      "           0.0403, -0.0132,  0.0218, -0.0257, -0.0527,  0.0162, -0.0798,\n",
      "          -0.0117, -0.1003, -0.0050,  0.0103,  0.0060,  0.0338, -0.0335,\n",
      "           0.0491,  0.0395,  0.0434,  0.0444,  0.0273,  0.0097,  0.0694,\n",
      "          -0.1030,  0.0270, -0.0190, -0.0049,  0.0131, -0.0526,  0.0109,\n",
      "          -0.0629,  0.0191,  0.0361,  0.0237, -0.0017, -0.0401, -0.0963,\n",
      "           0.0010,  0.0165, -0.0213,  0.0037, -0.0083, -0.0329, -0.0284,\n",
      "           0.0688, -0.0412,  0.0931,  0.0431,  0.0646,  0.0151, -0.0435,\n",
      "           0.0304, -0.0046,  0.0135, -0.0599, -0.0591,  0.0455, -0.0926,\n",
      "          -0.0337,  0.0732, -0.0310,  0.0012, -0.0511,  0.0136,  0.0238,\n",
      "           0.0415,  0.0026, -0.0374, -0.0178, -0.0280, -0.0169,  0.0508,\n",
      "           0.0224,  0.0114, -0.0110,  0.0428, -0.0432,  0.0358,  0.0322,\n",
      "          -0.0130,  0.0106,  0.0525, -0.0329,  0.0299,  0.0150,  0.0300,\n",
      "           0.0326,  0.0214, -0.0696,  0.0591, -0.0397,  0.0007, -0.0229,\n",
      "           0.0632,  0.0397,  0.0141, -0.0005, -0.0726,  0.0410, -0.0196,\n",
      "           0.0007,  0.0146,  0.0245,  0.0607,  0.0250,  0.0210, -0.0022,\n",
      "           0.0637, -0.0380,  0.0386,  0.0720,  0.0016,  0.0677,  0.0307,\n",
      "          -0.0534, -0.0046,  0.0103, -0.1342,  0.0375, -0.0129, -0.0254,\n",
      "          -0.0021, -0.0164,  0.0068, -0.0871, -0.0186,  0.0030,  0.0350,\n",
      "          -0.0170,  0.0409,  0.0408,  0.0317,  0.0606,  0.0024,  0.0729,\n",
      "           0.0743,  0.0217,  0.0266, -0.0491,  0.0632,  0.0272, -0.0571,\n",
      "           0.0069,  0.0169,  0.0033,  0.0403,  0.0681,  0.0228,  0.0154,\n",
      "           0.0058,  0.0752,  0.0427, -0.0062,  0.0421,  0.0045,  0.0412,\n",
      "          -0.0719,  0.0054, -0.0043, -0.0216,  0.0425, -0.0169, -0.0033,\n",
      "           0.0565, -0.1104, -0.0149, -0.0107,  0.0079, -0.0062, -0.0114,\n",
      "           0.0591, -0.0111,  0.0034, -0.0495,  0.0507, -0.0069,  0.0186,\n",
      "          -0.0292, -0.0191,  0.0327,  0.0189, -0.0107,  0.0247, -0.0371,\n",
      "          -0.0052,  0.0456, -0.0388, -0.0114, -0.0158, -0.0485, -0.0063,\n",
      "          -0.0439,  0.0115,  0.0483, -0.0197,  0.0609,  0.1439,  0.0452,\n",
      "           0.0420,  0.0011,  0.0498,  0.0571, -0.0219,  0.0060,  0.0598,\n",
      "          -0.0306,  0.0515,  0.0065, -0.0099,  0.0468,  0.0088,  0.0198,\n",
      "          -0.0056, -0.0171, -0.0227, -0.0528, -0.0076, -0.1033, -0.0034,\n",
      "          -0.0360, -0.0146, -0.0591,  0.0589, -0.0460,  0.0368,  0.0193,\n",
      "           0.0172, -0.0618, -0.0663, -0.0360,  0.0358,  0.0502,  0.0133,\n",
      "           0.0674,  0.0091,  0.0378, -0.0277, -0.0486,  0.0019, -0.0365,\n",
      "           0.0036, -0.0086,  0.0285,  0.0567,  0.0412,  0.0193,  0.0532,\n",
      "          -0.0029,  0.0565,  0.0631,  0.0289, -0.0056,  0.0291, -0.0306,\n",
      "          -0.0110,  0.0186,  0.0550,  0.0521, -0.0865,  0.0081,  0.0368,\n",
      "          -0.0288,  0.0099, -0.0312,  0.0163,  0.0403,  0.0002, -0.0052,\n",
      "          -0.0201, -0.0107,  0.0350, -0.0577,  0.0717, -0.0623,  0.0132,\n",
      "          -0.0399,  0.0144,  0.0329, -0.0348, -0.0172, -0.0072,  0.0008,\n",
      "           0.0127,  0.0057,  0.0445,  0.0208, -0.0131,  0.0132,  0.0541,\n",
      "          -0.0601,  0.0120, -0.0121,  0.0044, -0.0328,  0.0187, -0.0254,\n",
      "           0.0170,  0.0326,  0.0032, -0.0145,  0.0612, -0.0360,  0.0360,\n",
      "           0.0022, -0.0498,  0.0086, -0.0194,  0.0291, -0.0305, -0.0143,\n",
      "          -0.0251,  0.0373,  0.0136,  0.0459, -0.0078,  0.0488, -0.0331,\n",
      "           0.0246, -0.0161, -0.0198,  0.0842, -0.0333,  0.0299, -0.0046,\n",
      "          -0.0366,  0.0097, -0.0595,  0.0078, -0.0636,  0.0286, -0.0592,\n",
      "           0.0397,  0.0454, -0.0532, -0.0175,  0.0094, -0.0648,  0.0798,\n",
      "          -0.0501, -0.0511, -0.0767, -0.0213,  0.0384, -0.0155,  0.0614,\n",
      "          -0.0113,  0.0024,  0.0055,  0.0300,  0.0242,  0.0039, -0.0314,\n",
      "          -0.0068,  0.1010, -0.0112, -0.0129,  0.0058, -0.0536,  0.0395,\n",
      "          -0.0632,  0.0309, -0.0285,  0.0716,  0.0440,  0.0662, -0.0197,\n",
      "          -0.0319, -0.0302, -0.0166, -0.0103, -0.0089, -0.0129,  0.0063,\n",
      "          -0.0321, -0.0131,  0.0166, -0.0849, -0.0088, -0.0261, -0.0034,\n",
      "           0.0334, -0.0018, -0.0550, -0.0035,  0.0553, -0.0373, -0.0085,\n",
      "          -0.0972,  0.0939, -0.0074, -0.0045, -0.0301, -0.0093, -0.0082,\n",
      "          -0.0581]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "torch.Size([1, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "brain = A3C(num_actions=4).to(device)\n",
    "input_data = torch.randn(size=(3, 210, 160)).to(device)\n",
    "hidden = (Variable(torch.zeros(1, 1, 512).float().to(device=device)),Variable(torch.zeros(1, 1, 512).float().to(device=device)))\n",
    "print(input_data)\n",
    "print(input_data.shape)\n",
    "out_data, new_hidden = brain(data, hidden)\n",
    "print(out_data)\n",
    "print(out_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Parameter_server:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "    # 푸쉬와 풀, 업데이트의 개념을 잘 생각\n",
    "    \n",
    "    def updates_params(self, model):\n",
    "        self.params.append(model)\n",
    "    \n",
    "    def pull_params(self):\n",
    "        return self.params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Actor:\n",
    "    def __init__(self, params_server, actor_idx):\n",
    "        self.params_server = params_server\n",
    "        self.actor_idx = actor_idx # 몇 번째 에이전트인지 인덱스\n",
    "        self.device = 'cpu' # Actor의 프로세스는 cpu에 할당한다. Learner의 경우 gpu로 학습\n",
    "        self.actor_network = A3C(num_actions=4).to(self.device)\n",
    "        self.counter = 0\n",
    "    def explore(self): \n",
    "        while 1: # 카운터 변수를 통해 탐색 횟수 정하기?\n",
    "            time.sleep(5)\n",
    "            print(\"Explore..\")\n",
    "            self.pull_params()\n",
    "        pass\n",
    "    \n",
    "    def get_params_server(self):\n",
    "        return self.params_server\n",
    "    \n",
    "    def pull_params(self):\n",
    "        updated_params = ray.get(self.params_server.pull_params.remote()) #업데이트된 파라미터를 파라미터 서버로부터 가져온다\n",
    "        print(\"Parameter Type : \", type(updated_params))\n",
    "        self.actor_network.load_state_dict(updated_params)\n",
    "        print(f\"Model i supdated in actor number_{self.actor_idx}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner:\n",
    "    def __init__(self, params_server):\n",
    "        self.params_server = params_server\n",
    "        self.device = 'cuda:0'\n",
    "        \n",
    "        self.learner_network = A3C(num_actions=4).to(self.device)\n",
    "    \n",
    "    def get_params_server(self):\n",
    "        return self.params_server\n",
    "    \n",
    "    def push_parameters(self):\n",
    "        self.params_server.updates_params.remote(self.learner_network.cpu().state_dict())\n",
    "        \n",
    "    def pull_parameters_from_server(self):\n",
    "        return self.params_server.pull_params.remote()\n",
    "    \n",
    "    def train(self):\n",
    "        while 1:\n",
    "            time.sleep(2)\n",
    "            self.push_parameters()\n",
    "            print(\"Learner: Model parameter is sent to Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_input_size 22528\n",
      "linear_input_size 22528\n",
      "Actor(Parameter_server,ae935fc001000000)\n",
      "Actor(Parameter_server,ae935fc001000000)\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m linear_input_size 22528\n"
     ]
    }
   ],
   "source": [
    "# 파라미터 서버 선언\n",
    "params_server = Parameter_server.remote()\n",
    "\n",
    "learner = Learner(params_server)\n",
    "learner2 = Learner(params_server)\n",
    "actor = Actor.remote(params_server, 0)\n",
    "\n",
    "print(learner.get_params_server())\n",
    "print(learner2.get_params_server())\n",
    "#print(ray.get(actor.get_params_server.remote()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 업데이트를 3회 진행\n",
    "iteration = 3\n",
    "for _ in range(iteration): learner.push_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner에서 server의 파라미터를 가지고 와보는지 test, 실제로 러너는 서버에서 가지고 올 일이 없다.\n",
    "ray.get(learner.pull_parameters_from_server())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(84b65a94b96102243db7cfef0100000001000000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Parameter Type :  <class 'collections.OrderedDict'>\n",
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Model i supdated in actor number_0\n"
     ]
    }
   ],
   "source": [
    "# actor의 explore 메소드를 통해 learner로 부터 받은 parameter를 server를 통해 가져오고, actor의 모델로 저장이 되는지 테스트\n",
    "actor.explore.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=4276)\u001b[0m Explore..\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 13:50:10,702\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.22',\n",
       " 'raylet_ip_address': '192.168.0.22',\n",
       " 'redis_address': '192.168.0.22:6379',\n",
       " 'object_store_address': 'tcp://127.0.0.1:34771',\n",
       " 'raylet_socket_name': 'tcp://127.0.0.1:22897',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': 'C:\\\\Users\\\\KUKJIN~1\\\\AppData\\\\Local\\\\Temp\\\\ray\\\\session_2021-01-29_13-50-09_806950_39060',\n",
       " 'metrics_export_port': 18979,\n",
       " 'node_id': '3dfb39f49a0423c8102bab082bf47c05157616d7'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-29 13:50:14,119\tWARNING worker.py:1091 -- The dashboard on node DESKTOP-ESV82HP failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 962, in <module>\n",
      "    metrics_export_address=metrics_export_address)\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 512, in __init__\n",
      "    build_dir = setup_static_dir(self.app)\n",
      "  File \"c:\\users\\kukjinkim\\anaconda3\\envs\\minerl\\lib\\site-packages\\ray\\dashboard\\dashboard.py\", line 411, in setup_static_dir\n",
      "    \"&& npm run build)\", build_dir)\n",
      "FileNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/dashboard/client && npm ci && npm run build): 'c:\\\\users\\\\kukjinkim\\\\anaconda3\\\\envs\\\\minerl\\\\lib\\\\site-packages\\\\ray\\\\dashboard\\\\client/build'\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m F0129 14:48:46.111907 27380 34232 redis_client.cc:74]  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 2\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m *** Check failure stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B905052B  public: void __cdecl google::LogMessage::Flush(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B904F382  public: __cdecl google::LogMessage::~LogMessage(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B9021628  public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5E3C4  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5D507  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5CF54  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F590BC  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E91D3E  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E9BC41  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E5803A  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B92D3250  bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9B9777C24  BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9BB5AD4D1  RtlUserThreadStart\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m F0129 14:48:46.858430 32316 40188 redis_client.cc:74]  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 2\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m *** Check failure stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015E7E9B  public: void __cdecl google::LogMessage::Flush(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015E6CF2  public: __cdecl google::LogMessage::~LogMessage(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015AAE18  public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701483294  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7014823D7  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701481E24  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701479ABC  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF70142FAE7  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701324AC6  public: class google::NullStream & __ptr64 __cdecl google::NullStream::stream(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701886E90  bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9B9777C24  BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9BB5AD4D1  RtlUserThreadStart\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m F0129 14:52:28.458844 36300  9864 redis_client.cc:74]  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 3\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m *** Check failure stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B905052B  public: void __cdecl google::LogMessage::Flush(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B904F382  public: __cdecl google::LogMessage::~LogMessage(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B9021628  public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5E3C4  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5D507  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F5CF54  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8F590BC  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E91D3E  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E9BC41  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B8E5803A  public: class google::LogMessageVoidify & __ptr64 __cdecl google::LogMessageVoidify::operator=(class google::LogMessageVoidify const & __ptr64) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF6B92D3250  bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9B9777C24  BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9BB5AD4D1  RtlUserThreadStart\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m F0129 14:52:29.183845 48440 15296 redis_client.cc:74]  Check failed: num_attempts < RayConfig::instance().redis_db_connect_retries() Expected 1 Redis shard addresses, found 28429462282043508\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m *** Check failure stack trace: ***\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015E7E9B  public: void __cdecl google::LogMessage::Flush(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015E6CF2  public: __cdecl google::LogMessage::~LogMessage(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7015AAE18  public: virtual __cdecl google::NullStreamFatal::~NullStreamFatal(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701483294  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF7014823D7  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701481E24  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701479ABC  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF70142FAE7  public: class google::LogMessage::LogStream * __ptr64 __cdecl google::LogMessage::LogStream::self(void)const __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701324AC6  public: class google::NullStream & __ptr64 __cdecl google::NullStream::stream(void) __ptr64\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF701886E90  bool __cdecl google::Demangle(char const * __ptr64,char * __ptr64,int)\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9B9777C24  BaseThreadInitThunk\n",
      "\u001b[2m\u001b[36m(pid=None)\u001b[0m     @   00007FF9BB5AD4D1  RtlUserThreadStart\n"
     ]
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
